---
title: "Apache Kafka 입문: 이벤트 스트리밍의 기초"
date: "2024-01-26"
excerpt: "분산 이벤트 스트리밍 플랫폼인 Apache Kafka의 핵심 개념과 기본 사용법을 알아봅니다."
category: "Apache Kafka"
tags: ["Kafka", "Event Streaming", "Message Queue", "분산 시스템"]
author: "Kaameo"
---

Apache Kafka는 LinkedIn에서 개발한 분산 이벤트 스트리밍 플랫폼으로, 현재는 많은 기업에서 실시간 데이터 파이프라인과 스트리밍 애플리케이션을 구축하는 데 사용하고 있습니다.

## Kafka란 무엇인가?

Apache Kafka는 다음과 같은 특징을 가진 분산 이벤트 스트리밍 플랫폼입니다:

- **고성능**: 초당 수백만 건의 메시지 처리 가능
- **확장성**: 수평적 확장이 용이한 분산 시스템
- **내구성**: 메시지를 디스크에 저장하여 데이터 손실 방지
- **실시간 처리**: 낮은 지연시간으로 실시간 데이터 처리

## 핵심 개념

### 1. Producer와 Consumer

```
[Producer] --> [Kafka Cluster] --> [Consumer]
```

- **Producer**: 메시지를 생성하고 Kafka로 전송하는 애플리케이션
- **Consumer**: Kafka에서 메시지를 읽어 처리하는 애플리케이션

### 2. Topic과 Partition

- **Topic**: 메시지를 구분하는 카테고리 (예: "user-events", "order-events")
- **Partition**: Topic을 나누는 단위로, 병렬 처리와 확장성을 제공

```
Topic: user-events
├── Partition 0: [msg1, msg4, msg7, ...]
├── Partition 1: [msg2, msg5, msg8, ...]
└── Partition 2: [msg3, msg6, msg9, ...]
```

### 3. Consumer Group

여러 Consumer가 하나의 그룹으로 묶여 메시지를 분산 처리합니다.

## Kafka 설치 및 실행

### 1. Docker Compose로 Kafka 실행

```yaml
version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
  
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

### 2. Kafka 실행

```bash
# Docker Compose 실행
docker-compose up -d

# Topic 생성
docker exec -it kafka kafka-topics --create \
  --topic test-topic \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1
```

## Spring Boot에서 Kafka 사용하기

### 1. 의존성 추가

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

### 2. 설정 파일

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: my-consumer-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "*"
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
```

### 3. Producer 구현

```java
@Component
@Slf4j
public class EventProducer {
    
    private final KafkaTemplate<String, Object> kafkaTemplate;
    
    public EventProducer(KafkaTemplate<String, Object> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }
    
    public void sendUserEvent(UserEvent event) {
        String topic = "user-events";
        
        kafkaTemplate.send(topic, event.getUserId(), event)
            .addCallback(
                result -> log.info("메시지 전송 성공: {}", event),
                ex -> log.error("메시지 전송 실패: {}", event, ex)
            );
    }
}

@Data
@AllArgsConstructor
@NoArgsConstructor
public class UserEvent {
    private String userId;
    private String eventType;
    private LocalDateTime timestamp;
    private Map<String, Object> data;
}
```

### 4. Consumer 구현

```java
@Component
@Slf4j
public class EventConsumer {
    
    @KafkaListener(topics = "user-events", groupId = "user-service")
    public void consumeUserEvent(UserEvent event) {
        log.info("이벤트 수신: {}", event);
        
        // 이벤트 타입에 따른 처리
        switch (event.getEventType()) {
            case "USER_CREATED":
                handleUserCreated(event);
                break;
            case "USER_UPDATED":
                handleUserUpdated(event);
                break;
            case "USER_DELETED":
                handleUserDeleted(event);
                break;
            default:
                log.warn("알 수 없는 이벤트 타입: {}", event.getEventType());
        }
    }
    
    private void handleUserCreated(UserEvent event) {
        // 사용자 생성 이벤트 처리 로직
        log.info("새 사용자 생성: {}", event.getUserId());
    }
    
    private void handleUserUpdated(UserEvent event) {
        // 사용자 수정 이벤트 처리 로직
        log.info("사용자 정보 수정: {}", event.getUserId());
    }
    
    private void handleUserDeleted(UserEvent event) {
        // 사용자 삭제 이벤트 처리 로직
        log.info("사용자 삭제: {}", event.getUserId());
    }
}
```

## 실제 사용 사례

### 1. 실시간 로그 수집
```
Application Logs --> Kafka --> Elasticsearch --> Kibana
```

### 2. 이벤트 기반 마이크로서비스
```
Order Service --> Kafka --> Payment Service
                      └--> Inventory Service
                      └--> Notification Service
```

### 3. 실시간 데이터 분석
```
IoT Devices --> Kafka --> Stream Processing --> Dashboard
```

## 모니터링과 관리

### Kafka Manager UI 사용

```yaml
# docker-compose.yml에 추가
kafka-ui:
  image: provectuslabs/kafka-ui:latest
  ports:
    - "8090:8080"
  environment:
    KAFKA_CLUSTERS_0_NAME: local
    KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
```

브라우저에서 `http://localhost:8090`으로 접속하여 Kafka 클러스터를 모니터링할 수 있습니다.

## 성능 최적화 팁

### 1. Producer 최적화
```java
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
props.put(ProducerConfig.LINGER_MS_CONFIG, 10);
props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");
```

### 2. Consumer 최적화
```java
props.put(ConsumerConfig.FETCH_MIN_BYTES_CONFIG, 1024);
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);
```

## 주의사항

1. **메시지 순서**: 같은 파티션 내에서만 순서가 보장됨
2. **중복 처리**: At-least-once 전송 시 중복 처리 로직 필요
3. **메모리 관리**: 대용량 메시지 처리 시 메모리 설정 조정 필요

## 마무리

Apache Kafka는 대규모 실시간 데이터 처리에 매우 효과적인 플랫폼입니다. 
이번 포스트에서는 기본 개념과 Spring Boot에서의 사용법을 알아봤습니다.

다음 포스트에서는 Kafka Streams를 사용한 실시간 스트림 처리에 대해 다루도록 하겠습니다!

## 참고 자료
- [Apache Kafka 공식 문서](https://kafka.apache.org/documentation/)
- [Spring for Apache Kafka](https://spring.io/projects/spring-kafka)
- [Confluent Kafka Tutorial](https://kafka-tutorials.confluent.io/)