---
title: "Apache Kafka 기초: 실시간 데이터 스트리밍 시작하기"
date: "2024-01-26"
excerpt: "Apache Kafka의 핵심 개념을 이해하고 Spring Boot와 함께 사용하는 방법을 알아봅니다."
category: "Apache Kafka"
tags: ["Streaming", "Spring Boot", "Message Queue"]
author: "Kaameo"
---

Apache Kafka는 LinkedIn에서 개발한 분산 스트리밍 플랫폼으로, 대용량 실시간 데이터 처리에 널리 사용됩니다.

## Kafka의 핵심 개념

### Producer와 Consumer

Producer는 메시지를 생성하여 Kafka로 전송하고, Consumer는 Kafka에서 메시지를 읽어 처리합니다.

### Topic과 Partition

Topic은 메시지를 구분하는 카테고리이며, Partition은 Topic을 나누어 병렬 처리를 가능하게 합니다.

### Consumer Group

여러 Consumer가 하나의 그룹으로 묶여 메시지를 분산 처리할 수 있습니다.

## Docker로 Kafka 실행하기

docker-compose.yml 파일을 작성합니다:

```yaml
version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
  
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

실행 명령어:

```bash
docker-compose up -d
```

## Spring Boot에서 Kafka 사용하기

### 의존성 추가

pom.xml에 다음 의존성을 추가합니다:

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

### application.yml 설정

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: my-group
      auto-offset-reset: earliest
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
```

### Producer 구현

```java
@Component
public class KafkaProducer {
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    public void sendMessage(String topic, String message) {
        kafkaTemplate.send(topic, message);
    }
}
```

### Consumer 구현

```java
@Component
public class KafkaConsumer {
    
    @KafkaListener(topics = "my-topic", groupId = "my-group")
    public void consume(String message) {
        System.out.println("Received message: " + message);
    }
}
```

## 실제 사용 사례

### 로그 수집 시스템

애플리케이션 로그를 Kafka로 전송하고, 이를 Elasticsearch에 저장하여 분석할 수 있습니다.

### 이벤트 기반 아키텍처

마이크로서비스 간 비동기 통신을 위해 Kafka를 이벤트 버스로 활용할 수 있습니다.

### 실시간 데이터 분석

IoT 센서 데이터나 사용자 행동 데이터를 실시간으로 수집하고 분석할 수 있습니다.

## 성능 최적화 팁

### Producer 최적화

- batch.size를 늘려 처리량 향상
- linger.ms 설정으로 배치 처리 최적화
- compression.type 설정으로 네트워크 사용량 감소

### Consumer 최적화

- fetch.min.bytes 조정으로 네트워크 효율성 향상
- max.poll.records 설정으로 처리량 제어
- 적절한 파티션 수 설정으로 병렬 처리 최적화

## 모니터링

Kafka Manager나 Kafka UI 같은 도구를 사용하여 클러스터 상태를 모니터링할 수 있습니다.

## 마무리

Apache Kafka는 대규모 실시간 데이터 처리에 매우 효과적인 플랫폼입니다. 
기본 개념을 이해하고 Spring Boot와 함께 사용하면 강력한 스트리밍 애플리케이션을 구축할 수 있습니다.

다음 포스트에서는 Kafka Streams API를 활용한 고급 스트림 처리에 대해 알아보겠습니다!